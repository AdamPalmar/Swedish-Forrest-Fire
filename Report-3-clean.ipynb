{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Collection of functions and tools for the needs of 02450 Introduction to Machine Learning course.'''\n",
    "from pylab import *\n",
    "\n",
    "def remove_zero_cols(m):\n",
    "    '''Function removes from given matrix m the column vectors containing only zeros.'''\n",
    "    rows = range(m.shape[0])\n",
    "    cols = np.nonzero(sum(abs(m)))[1].tolist()[0]\n",
    "    return m[np.ix_(rows,cols)]\n",
    "\n",
    "def remove_zero_rows(m):\n",
    "    '''Function removes from given matrix m the row vectors containing only zeros.'''\n",
    "    rows = np.nonzero(sum(abs(m.T)).T)[0].tolist()[0]\n",
    "    cols = range(m.shape[1])\n",
    "    return m[np.ix_(rows,cols)]\n",
    "\n",
    "def remove_zero_rows_and_cols(m):\n",
    "    '''Function removes from given matrix m the row vectors and the column vectors containing only zeros.'''\n",
    "    rows = np.nonzero(sum(abs(m.T)).T)[0].tolist()[0]\n",
    "    cols = np.nonzero(sum(abs(m)))[1].tolist()[0]\n",
    "    return m[np.ix_(rows,cols)]\n",
    "\n",
    "\n",
    "def bmplot(yt, xt, X):\n",
    "    ''' Function plots matrix X as image with lines separating fields. '''\n",
    "    imshow(X,interpolation='none',cmap='bone')\n",
    "    xticks(range(0,len(xt)), xt)\n",
    "    yticks(range(0,len(yt)), yt)\n",
    "    for i in range(0,len(yt)):\n",
    "        axhline(i-0.5, color='black')\n",
    "    for i in range(0,len(xt)):\n",
    "        axvline(i-0.5, color='black')\n",
    "\n",
    "\n",
    "def glm_validate(X,y,cvf=10):\n",
    "    ''' Validate linear regression model using 'cvf'-fold cross validation.\n",
    "        The loss function computed as mean squared error on validation set (MSE).\n",
    "        Function returns MSE averaged over 'cvf' folds.\n",
    "\n",
    "        Parameters:\n",
    "        X       training data set\n",
    "        y       vector of values\n",
    "        cvf     number of crossvalidation folds        \n",
    "    '''\n",
    "    from sklearn import cross_validation, linear_model\n",
    "    CV = cross_validation.KFold(X.shape[0],cvf)\n",
    "    validation_error=np.empty(cvf)\n",
    "    f=0\n",
    "    for train_index, test_index in CV:\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        m = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "        validation_error[f] = np.square(y_test-m.predict(X_test)).sum()/y_test.shape[0]\n",
    "        f=f+1\n",
    "    return validation_error.mean()\n",
    "        \n",
    "\n",
    "def feature_selector_lr(X,y,cvf=10,features_record=None,loss_record=None):\n",
    "    ''' Function performs feature selection for linear regression model using\n",
    "        'cvf'-fold cross validation. The process starts with empty set of\n",
    "        features, and in every recurrent step one feature is added to the set\n",
    "        (the feature that minimized loss function in cross-validation.)\n",
    "\n",
    "        Parameters:\n",
    "        X       training data set\n",
    "        y       vector of values\n",
    "        cvf     number of crossvalidation folds\n",
    "\n",
    "        Returns:\n",
    "        selected_features   indices of optimal set of features\n",
    "        features_record     boolean matrix where columns correspond to features\n",
    "                            selected in subsequent steps\n",
    "        loss_record         vector with cv errors in subsequent steps\n",
    "        \n",
    "        Example:\n",
    "        selected_features, features_record, loss_record = ...\n",
    "            feature_selector_lr(X_train, y_train, cvf=10)\n",
    "            \n",
    "    ''' \n",
    "\n",
    "    # first iteration error corresponds to no-feature estimator\n",
    "    if loss_record==None:\n",
    "        loss_record = np.array([np.square(y-y.mean()).sum()/y.shape[0]])\n",
    "    if features_record==None:\n",
    "        features_record = np.zeros((X.shape[1],1))\n",
    "\n",
    "    # Add one feature at a time to find the most significant one.\n",
    "    # Include only features not added before.\n",
    "    selected_features = features_record[:,-1].nonzero()[0]\n",
    "    min_loss = loss_record[-1]\n",
    "    print(min_loss)\n",
    "    best_feature = False\n",
    "    for feature in range(0,X.shape[1]):\n",
    "        if np.where(selected_features==feature)[0].size==0:\n",
    "            trial_selected = np.concatenate((selected_features,np.array([feature])),0).astype(int)\n",
    "            # validate selected features with linear regression and cross-validation:\n",
    "            trial_loss = glm_validate(X[:,trial_selected],y,cvf)\n",
    "            print(trial_loss)\n",
    "            if trial_loss<min_loss:\n",
    "                min_loss = trial_loss \n",
    "                best_feature = feature\n",
    "\n",
    "    # If adding extra feature decreased the loss function, update records\n",
    "    # and go to the next recursive step\n",
    "    if best_feature!=False:\n",
    "        features_record = np.concatenate((features_record, np.array([features_record[:,-1]]).T), 1)\n",
    "        features_record[best_feature,-1]=1\n",
    "        loss_record = np.concatenate((loss_record,np.array([min_loss])),0)\n",
    "        selected_features, features_record, loss_record = feature_selector_lr(X,y,cvf,features_record,loss_record)\n",
    "        \n",
    "    # Return current records and terminate procedure\n",
    "    return selected_features, features_record, loss_record\n",
    "        \n",
    "\n",
    "def rlr_validate(X,y,lambdas,cvf=10):\n",
    "    ''' Validate regularized linear regression model using 'cvf'-fold cross validation.\n",
    "        Find the optimal lambda (minimizing validation error) from 'lambdas' list.\n",
    "        The loss function computed as mean squared error on validation set (MSE).\n",
    "        Function returns: MSE averaged over 'cvf' folds, optimal value of lambda,\n",
    "        average weight values for all lambdas, MSE train&validation errors for all lambdas.\n",
    "\n",
    "        Parameters:\n",
    "        X       training data set\n",
    "        y       vector of values\n",
    "        lambdas vector of lambda values to be validated\n",
    "        cvf     number of crossvalidation folds     \n",
    "        \n",
    "        Returns:\n",
    "        opt_val_err         validation error for optimum lambda\n",
    "        opt_lambda          value of optimal lambda\n",
    "        mean_w_vs_lambda    weights as function of lambda (matrix)\n",
    "        train_err_vs_lambda train error as function of lambda (vector)\n",
    "        test_err_vs_lambda  test error as function of lambda (vector)\n",
    "    '''\n",
    "    from sklearn import cross_validation\n",
    "    CV = cross_validation.KFold(X.shape[0],cvf)\n",
    "    M = X.shape[1]\n",
    "    w = np.empty((M,cvf,len(lambdas)))\n",
    "    train_error = np.empty((cvf,len(lambdas)))\n",
    "    test_error = np.empty((cvf,len(lambdas)))\n",
    "    f = 0\n",
    "    for train_index, test_index in CV:\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        # precompute terms\n",
    "        Xty = X_train.T*y_train\n",
    "        XtX = X_train.T*X_train\n",
    "\n",
    "        for l in range(0,len(lambdas)):\n",
    "            # Compute parameters for current value of lambda and current CV fold\n",
    "            # note: \"linalg.lstsq(a,b)\" is substitue for Matlab's left division operator \"\\\"\n",
    "            w[:,f,l] = linalg.lstsq(XtX+lambdas[l]*np.eye(M),Xty)[0].A.squeeze()\n",
    "            # Evaluate training and test performance\n",
    "            train_error[f,l] = np.power(y_train-X_train*np.mat(w[:,f,l]).T,2).sum()/y_train.shape[0]\n",
    "            test_error[f,l] = np.power(y_test-X_test*np.mat(w[:,f,l]).T,2).sum()/y_test.shape[0]\n",
    "    \n",
    "        f=f+1\n",
    "\n",
    "    opt_val_err = np.min(np.mean(test_error,0))\n",
    "    opt_lambda = lambdas[np.argmin(np.mean(test_error,0))]\n",
    "    train_err_vs_lambda = np.mean(train_error,0)\n",
    "    test_err_vs_lambda = np.mean(test_error,0)\n",
    "    mean_w_vs_lambda = np.squeeze(np.mean(w,1))\n",
    "    \n",
    "    return opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda\n",
    "        \n",
    "def dbplotf(X,y,fun,grid_range,resolution=100) :     \n",
    "    # smoothness of color-coding:\n",
    "    levels = 100\n",
    "    # convert from one-out-of-k encoding, if neccessary:\n",
    "    if y.shape[1]>1: y = argmax(y,1)\n",
    "    # compute grid range if not given explicitly:\n",
    "    if grid_range=='auto':\n",
    "        grid_range = [X.min(0)[0,0], X.max(0)[0,0], X.min(0)[0,1], X.max(0)[0,1]]\n",
    "        \n",
    "    delta_f1 = np.float(grid_range[1]-grid_range[0])/resolution\n",
    "    delta_f2 = np.float(grid_range[3]-grid_range[2])/resolution\n",
    "    f1 = arange(grid_range[0],grid_range[1],delta_f1)\n",
    "    f2 = arange(grid_range[2],grid_range[3],delta_f2)\n",
    "    F1, F2 = meshgrid(f1, f2)\n",
    "    C = len(np.unique(y.A).tolist())\n",
    "    # adjust color coding:\n",
    "    if C==2: C_colors = ['b', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)']; C_levels = [.5]\n",
    "    if C==3: C_colors = ['b', 'g', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)', 'Class C (y=2)']; C_levels = [.66, 1.34]\n",
    "    if C==4: C_colors = ['b', 'w', 'y', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)', 'Class C (y=2)', 'Class D (y=3)']; C_levels = [.74, 1.5, 2.26]\n",
    "    if C>4:\n",
    "        for c in range(C):\n",
    "            C_colors[c] = cm.jet.__call__(c*255/(C-1))[:3]\n",
    "            C_legend[c] = 'Class {0}'.format(c)\n",
    "        C_levels = [0]\n",
    "        \n",
    "    coords = np.mat( [[f1[i], f2[j]] for i in range(len(f1)) for j in range(len(f2))] )\n",
    "    values_list = fun(coords)#np.mat(classifier.predict(coords))\n",
    "    if type(values_list) != matrix : values_list = np.asmatrix(values_list)\n",
    "    \n",
    "    if values_list.shape[0]!=len(f1)*len(f2): values_list = values_list.T\n",
    "    values = np.asarray(np.reshape(values_list,(len(f1),len(f2))).T)\n",
    "            \n",
    "    hold(True)\n",
    "    for c in range(C):\n",
    "        cmask = (y==c).A.ravel(); plot(X[cmask,0].A, X[cmask,1].A, '.', color=C_colors[c], markersize=10)\n",
    "    title('Model prediction and decision boundary')\n",
    "    xlabel('Feature 1'); ylabel('Feature 2');\n",
    "    contour(F1, F2, values, levels=C_levels, colors=['k'], linestyles='dashed')\n",
    "    contourf(F1, F2, values, levels=linspace(values.min(),values.max(),levels), cmap=cm.jet, origin='image')\n",
    "    colorbar(format='%.1f'); legend(C_legend)\n",
    "    hold(False) \n",
    " \n",
    "def dbplot(classifier, X, y, grid_range, resolution=100):\n",
    "    ''' Plot decision boundry for given binomial or multinomial classifier '''\n",
    "\n",
    "    # smoothness of color-coding:\n",
    "    levels = 100\n",
    "    # convert from one-out-of-k encoding, if neccessary:\n",
    "    if y.shape[1]>1: y = argmax(y,1)\n",
    "    # compute grid range if not given explicitly:\n",
    "    if grid_range=='auto':\n",
    "        grid_range = [X.min(0)[0,0], X.max(0)[0,0], X.min(0)[0,1], X.max(0)[0,1]]\n",
    "        \n",
    "    delta_f1 = np.float(grid_range[1]-grid_range[0])/resolution\n",
    "    delta_f2 = np.float(grid_range[3]-grid_range[2])/resolution\n",
    "    f1 = arange(grid_range[0],grid_range[1],delta_f1)\n",
    "    f2 = arange(grid_range[2],grid_range[3],delta_f2)\n",
    "    F1, F2 = meshgrid(f1, f2)\n",
    "    C = len(np.unique(y.A).tolist())\n",
    "    # adjust color coding:\n",
    "    if C==2: C_colors = ['b', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)']; C_levels = [.5]\n",
    "    if C==3: C_colors = ['b', 'g', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)', 'Class C (y=2)']; C_levels = [.66, 1.34]\n",
    "    if C==4: C_colors = ['b', 'w', 'y', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)', 'Class C (y=2)', 'Class D (y=3)']; C_levels = [.74, 1.5, 2.26]\n",
    "    if C>4:\n",
    "        for c in range(C):\n",
    "            C_colors[c] = cm.jet.__call__(c*255/(C-1))[:3]\n",
    "            C_legend[c] = 'Class {0}'.format(c)\n",
    "        C_levels = [0]\n",
    "\n",
    "    coords = np.mat( [[f1[i], f2[j]] for i in range(len(f1)) for j in range(len(f2))] )\n",
    "    values_list = np.mat(classifier.predict(coords))\n",
    "    if values_list.shape[0]!=len(f1)*len(f2): values_list = values_list.T\n",
    "    values = np.asarray(np.reshape(values_list,(len(f1),len(f2))).T)\n",
    "            \n",
    "    hold(True)\n",
    "    for c in range(C):\n",
    "        cmask = (y==c).A.ravel(); plot(X[cmask,0].A, X[cmask,1].A, '.', color=C_colors[c], markersize=10)\n",
    "    title('Model prediction and decision boundary')\n",
    "    xlabel('Feature 1'); ylabel('Feature 2');\n",
    "    contour(F1, F2, values, levels=C_levels, colors=['k'], linestyles='dashed')\n",
    "    contourf(F1, F2, values, levels=linspace(values.min(),values.max(),levels), cmap=cm.jet, origin='image')\n",
    "    colorbar(format='%.1f'); legend(C_legend)\n",
    "    hold(False)\n",
    "\n",
    "\n",
    "def dbprobplot(classifier, X, y, grid_range, resolution=100):\n",
    "    ''' Plot decision boundry for given binomial classifier '''\n",
    "\n",
    "    # smoothness of color-coding:\n",
    "    levels = 100\n",
    "    # convert from one-out-of-k encoding, if neccessary:\n",
    "    if y.shape[1]>1: y = argmax(y,1)\n",
    "    # compute grid range if not given explicitly:\n",
    "    if grid_range=='auto':\n",
    "        grid_range = [X.min(0)[0,0], X.max(0)[0,0], X.min(0)[0,1], X.max(0)[0,1]]\n",
    "    # if more than two classes, display the first class against the rest:\n",
    "    y[y>1]=1        \n",
    "    C=2; C_colors = ['b', 'r']; C_legend = ['Class A (y=0)', 'Class B (y=1)']; C_levels = [.5]\n",
    "        \n",
    "    delta_f1 = np.float(grid_range[1]-grid_range[0])/resolution\n",
    "    delta_f2 = np.float(grid_range[3]-grid_range[2])/resolution\n",
    "    f1 = arange(grid_range[0],grid_range[1],delta_f1)\n",
    "    f2 = arange(grid_range[2],grid_range[3],delta_f2)\n",
    "    F1, F2 = meshgrid(f1, f2)\n",
    "\n",
    "    coords = np.mat( [[f1[i], f2[j]] for i in range(len(f1)) for j in range(len(f2))] )\n",
    "    values_list = classifier.predict_proba(coords)\n",
    "    if values_list.shape[0]!=len(f1)*len(f2): values_list = values_list.T\n",
    "    values_list = 1-values_list[:,0] # probability of class being y=1\n",
    "    values = np.asarray(np.reshape(values_list,(len(f1),len(f2))).T)\n",
    "           \n",
    "    hold(True)\n",
    "    for c in range(C):\n",
    "        cmask = (y==c).A.ravel(); plot(X[cmask,0].A, X[cmask,1].A, '.', color=C_colors[c], markersize=10)\n",
    "    title('Model prediction and decision boundary')\n",
    "    xlabel('Feature 1'); ylabel('Feature 2');\n",
    "    \n",
    "    contour(F1, F2, values, levels=C_levels, colors=['k'], linestyles='dashed')\n",
    "    contourf(F1, F2, values, levels=linspace(values.min(),values.max(),levels), cmap=cm.jet, origin='image')\n",
    "    colorbar(format='%.1f'); legend(C_legend)\n",
    "    hold(False)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def rocplot(p, y):\n",
    "    '''\n",
    "    function: AUC, TPR, FPR = rocplot(p, y)\n",
    "    ROCPLOT Plots the receiver operating characteristic (ROC) curve and\n",
    "    calculates the area under the curve (AUC). \n",
    "\n",
    "    Notice that the function assumes values of p are all distinct. \n",
    "\n",
    "    \n",
    "    Usage:\n",
    "        rocplot(p, y)\n",
    "        AUC, TPR, FDR = rocplot(p, y)\n",
    " \n",
    "     Input: \n",
    "         p: Estimated probability of class 1. (Between 0 and 1.)\n",
    "         y: True class indices. (Equal to 0 or 1.)\n",
    "\n",
    "    Output:\n",
    "        AUC: The area under the ROC curve\n",
    "        TPR: True positive rate\n",
    "        FPR: False positive rate\n",
    "    '''\n",
    "    #ind = np.argsort(p,0)\n",
    "    #x = y[ind].A.ravel()\n",
    "    #FNR = np.mat(np.cumsum(x==1, 0, dtype=float)).T / np.sum(x==1,0)\n",
    "    #TPR = 1 - FNR\n",
    "    #TNR = np.mat(np.cumsum(x==0, 0, dtype=float)).T / np.sum(x==0,0)\n",
    "    #FPR = 1 - TNR\n",
    "    #onemat = np.mat([1]) \n",
    "    #TPR = np.bmat('onemat; TPR'); FPR = np.mat('onemat; FPR') # Don't get this line.\n",
    "    #TPR = vstack( (np.ones(1), TPR))\n",
    "    #FPR = vstack( (np.ones(1), FPR))\n",
    "    \n",
    "    #AUC = -np.diff(FPR,axis=0).T * (TPR[0:-1]+TPR[1:])/2\n",
    "    #AUC = AUC[0,0]    \n",
    "\n",
    "    #%%\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y.A.ravel(),p.A.ravel())\n",
    "    #FPR = fpr \n",
    "    #TPR = TPR\n",
    "    #TPR\n",
    "    AUC = metrics.roc_auc_score(y.A.ravel(), p.A.ravel())\n",
    "    #%%\n",
    "    plot(fpr, tpr, 'r', [0, 1], [0, 1], 'k')\n",
    "    grid()\n",
    "    xlim([-0.01,1.01]); ylim([-0.01,1.01])\n",
    "    xticks(arange(0,1.1,.1)); yticks(arange(0,1.1,.1))\n",
    "    xlabel('False positive rate (1-Specificity)')\n",
    "    ylabel('True positive rate (Sensitivity)')\n",
    "    title('Receiver operating characteristic (ROC)\\n AUC={:.3f}'.format(AUC))    \n",
    "    \n",
    "    \n",
    "    return AUC, tpr, fpr\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def confmatplot(y_true, y_est):\n",
    "    '''\n",
    "    The function plots confusion matrix for classification results. \n",
    "    \n",
    "    Usage:\n",
    "        confmatplot(y_true, y_estimated)\n",
    " \n",
    "     Input: \n",
    "         y_true: Vector of true class labels.\n",
    "         y_estimated: Vector of estimated class labels.\n",
    "    '''\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    y_true = np.asarray(y_true).ravel(); y_est = np.asarray(y_est).ravel()\n",
    "    C = unique(y_true).shape[0]\n",
    "    cm = confusion_matrix(y_true, y_est);\n",
    "    accuracy = 100*cm.diagonal().sum()/cm.sum(); error_rate = 100-accuracy;\n",
    "    imshow(cm, cmap='binary', interpolation='None');\n",
    "    colorbar(format='%.2f')\n",
    "    xticks(range(C)); yticks(range(C));\n",
    "    xlabel('Predicted class'); ylabel('Actual class');\n",
    "    title('Confusion matrix (Accuracy: {:}%, Error Rate: {:}%)'.format(accuracy, error_rate));\n",
    "    \n",
    "\n",
    "def bootstrap(X, y, N, weights='auto'):\n",
    "    '''\n",
    "    function: X_bs, y_bs = bootstrap(X, y, N, weights)\n",
    "    The function extracts the bootstrap set from given matrices X and y.\n",
    "    The distribution of samples is determined by weights parameter\n",
    "    (default: 'auto', equal weights). \n",
    "    \n",
    "    Usage:\n",
    "        X_bs, y_bs = bootstrap(X, y, N, weights)\n",
    " \n",
    "     Input: \n",
    "         X: Estimated probability of class 1. (Between 0 and 1.)\n",
    "         y: True class indices. (Equal to 0 or 1.)\n",
    "         N: number of samples to be drawn\n",
    "         weights: probability of occurence of samples (default: equal)\n",
    "\n",
    "    Output:\n",
    "        X_bs: Matrix with rows drawn randomly from X wrt given distribution\n",
    "        y_bs: Matrix with rows drawn randomly from y wrt given distribution\n",
    "    '''\n",
    "    if weights=='auto':\n",
    "        weights = np.ones((X.shape[0],1),dtype=float)/X.shape[0]\n",
    "    else:\n",
    "        weights = np.array(weights,dtype=float)\n",
    "        weights = (weights/weights.sum()).ravel().tolist()\n",
    "\n",
    "    #bc = np.random.multinomial(N, weights, 1).ravel()\n",
    "    \n",
    "    #selected_indices = [] \n",
    "    #while bc.sum()>0:\n",
    "    #     selected_indices += np.where(bc>0)[0].tolist(); bc[bc>0]-=1\n",
    "    #np.random.shuffle(selected_indices)\n",
    "        \n",
    "    selected_indices = np.random.choice(range(N), size=(N,1), replace=True,p=weights).flatten()\n",
    "    return X[selected_indices, :], y[selected_indices, :]\n",
    "  \n",
    "\n",
    "def clusterplot(X, clusterid, centroids='None', y='None', covars='None'):\n",
    "    '''\n",
    "    CLUSTERPLOT Plots a clustering of a data set as well as the true class\n",
    "    labels. If data is more than 2-dimensional it should be first projected\n",
    "    onto the first two principal components. Data objects are plotted as a dot\n",
    "    with a circle around. The color of the dot indicates the true class,\n",
    "    and the cicle indicates the cluster index. Optionally, the centroids are\n",
    "    plotted as filled-star markers, and ellipsoids corresponding to covariance\n",
    "    matrices (e.g. for gaussian mixture models).\n",
    "\n",
    "    Usage:\n",
    "    clusterplot(X, clusterid)\n",
    "    clusterplot(X, clusterid, centroids=c_matrix, y=y_matrix)\n",
    "    clusterplot(X, clusterid, centroids=c_matrix, y=y_matrix, covars=c_tensor)\n",
    "    \n",
    "    Input:\n",
    "    X           N-by-M data matrix (N data objects with M attributes)\n",
    "    clusterid   N-by-1 vector of cluster indices\n",
    "    centroids   K-by-M matrix of cluster centroids (optional)\n",
    "    y           N-by-1 vector of true class labels (optional)\n",
    "    covars      M-by-M-by-K tensor of covariance matrices (optional)\n",
    "    '''\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    cls = np.asarray(clusterid)\n",
    "    if y=='None':\n",
    "        y = np.zeros((X.shape[0],1))\n",
    "    else:\n",
    "        y = np.asarray(y)\n",
    "    if centroids!='None':\n",
    "        centroids = np.asarray(centroids)\n",
    "    K = np.size(np.unique(cls))\n",
    "    C = np.size(np.unique(y))\n",
    "    ncolors = np.max([C,K])\n",
    "    \n",
    "    # plot data points color-coded by class, cluster markers and centroids\n",
    "    hold(True)\n",
    "    colors = [0]*ncolors\n",
    "    for color in range(ncolors):\n",
    "        colors[color] = cm.jet.__call__(color*255/(ncolors-1))[:3]\n",
    "    for i,cs in enumerate(np.unique(y)):\n",
    "        plot(X[(y==cs).ravel(),0], X[(y==cs).ravel(),1], 'o', markeredgecolor='k', markerfacecolor=colors[i],markersize=6, zorder=2)\n",
    "    for i,cr in enumerate(np.unique(cls)):\n",
    "        plot(X[(cls==cr).ravel(),0], X[(cls==cr).ravel(),1], 'o', markersize=12, markeredgecolor=colors[i], markerfacecolor='None', markeredgewidth=3, zorder=1)\n",
    "    if centroids!='None':        \n",
    "        for cd in range(centroids.shape[0]):\n",
    "            plot(centroids[cd,0], centroids[cd,1], '*', markersize=22, markeredgecolor='k', markerfacecolor=colors[cd], markeredgewidth=2, zorder=3)\n",
    "    # plot cluster shapes:\n",
    "    if covars!='None':\n",
    "        for cd in range(centroids.shape[0]):\n",
    "            x1, x2 = gauss_2d(centroids[cd],covars[cd,:,:])\n",
    "            plot(x1,x2,'-', color=colors[cd], linewidth=3, zorder=5)\n",
    "    hold(False)\n",
    "\n",
    "    # create legend        \n",
    "    legend_items = np.unique(y).tolist()+np.unique(cls).tolist()+np.unique(cls).tolist()\n",
    "    for i in range(len(legend_items)):\n",
    "        if i<C: legend_items[i] = 'Class: {0}'.format(legend_items[i]);\n",
    "        elif i<C+K: legend_items[i] = 'Cluster: {0}'.format(legend_items[i]);\n",
    "        else: legend_items[i] = 'Centroid: {0}'.format(legend_items[i]);\n",
    "    legend(legend_items, numpoints=1, markerscale=.75, prop={'size': 9})\n",
    "\n",
    "\n",
    "def gauss_2d(centroid, ccov, std=2, points=100):\n",
    "    ''' Returns two vectors representing slice through gaussian, cut at given standard deviation. '''\n",
    "    mean = np.c_[centroid]; tt = np.c_[np.linspace(0, 2*np.pi, points)]\n",
    "    x = np.cos(tt); y=np.sin(tt); ap = np.concatenate((x,y), axis=1).T\n",
    "    d, v = np.linalg.eig(ccov); d = std * np.sqrt(np.diag(d))\n",
    "    bp = np.dot(v, np.dot(d, ap)) + np.tile(mean, (1, ap.shape[1])) \n",
    "    return bp[0,:], bp[1,:]\n",
    "    \n",
    "import sklearn.metrics.cluster as cluster_metrics\n",
    "    \n",
    "def clusterval(y, clusterid):\n",
    "    '''\n",
    "    CLUSTERVAL Estimate cluster validity using Entropy, Purity, Rand Statistic,\n",
    "    and Jaccard coefficient.\n",
    "    \n",
    "    Usage:\n",
    "      Entropy, Purity, Rand, Jaccard = clusterval(y, clusterid);\n",
    "    \n",
    "    Input:\n",
    "       y         N-by-1 vector of class labels \n",
    "       clusterid N-by-1 vector of cluster indices\n",
    "    \n",
    "    Output:\n",
    "      Entropy    Entropy measure.\n",
    "      Purity     Purity measure.\n",
    "      Rand       Rand index.\n",
    "      Jaccard    Jaccard coefficient.\n",
    "    '''\n",
    "    NMI = cluster_metrics.supervised.normalized_mutual_info_score(y.A.ravel(),clusterid)\n",
    "    \n",
    "    y = np.asarray(y).ravel(); clusterid = np.asarray(clusterid).ravel()\n",
    "    C = np.unique(y).size; K = np.unique(clusterid).size; N = y.shape[0]\n",
    "    EPS = 2.22e-16\n",
    "    \n",
    "    p_ij = np.zeros((K,C))          # probability that member of i'th cluster belongs to j'th class\n",
    "    m_i = np.zeros((K,1))           # total number of objects in i'th cluster\n",
    "    for k in range(K):\n",
    "        m_i[k] = (clusterid==k).sum()\n",
    "        yk = y[clusterid==k]\n",
    "        for c in range(C):\n",
    "            m_ij = (yk==c).sum()    # number of objects of j'th class in i'th cluster\n",
    "            p_ij[k,c] = m_ij.astype(float)/m_i[k]\n",
    "    entropy = ( (1-(p_ij*np.log2(p_ij+EPS)).sum(axis=1))*m_i.T ).sum() / (N*K) \n",
    "    purity = ( p_ij.max(axis=1) ).sum() / K\n",
    "\n",
    "    f00=0; f01=0; f10=0; f11=0\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            if y[i]!=y[j] and clusterid[i]!=clusterid[j]: f00 += 1;     # different class, different cluster    \n",
    "            elif y[i]==y[j] and clusterid[i]==clusterid[j]: f11 += 1;   # same class, same cluster\n",
    "            elif y[i]==y[j] and clusterid[i]!=clusterid[j]: f10 += 1;   # same class, different cluster    \n",
    "            else: f01 +=1;                                              # different class, same cluster\n",
    "    rand = np.float(f00+f11)/(f00+f01+f10+f11)\n",
    "    jaccard = np.float(f11)/(f01+f10+f11)\n",
    "\n",
    "    return rand, jaccard, NMI\n",
    "\n",
    "    \n",
    "def gausKernelDensity(X,width):\n",
    "    '''\n",
    "    GAUSKERNELDENSITY Calculate efficiently leave-one-out Gaussian Kernel Density estimate\n",
    "    Input: \n",
    "      X        N x M data matrix\n",
    "      width    variance of the Gaussian kernel\n",
    "    \n",
    "    Output: \n",
    "      density        vector of estimated densities\n",
    "      log_density    vector of estimated log_densities\n",
    "    '''\n",
    "    X = np.mat(np.asarray(X))\n",
    "    N,M = X.shape\n",
    "\n",
    "    # Calculate squared euclidean distance between data points\n",
    "    # given by ||x_i-x_j||_F^2=||x_i||_F^2-2x_i^Tx_j+||x_i||_F^2 efficiently\n",
    "    x2 = np.square(X).sum(axis=1)\n",
    "    D = x2[:,[0]*N] - 2*X.dot(X.T) + x2[:,[0]*N].T\n",
    "\n",
    "    # Evaluate densities to each observation\n",
    "    Q = np.exp(-1/(2.0*width)*D)\n",
    "    # do not take density generated from the data point itself into account\n",
    "    Q[np.diag_indices_from(Q)]=0\n",
    "    sQ = Q.sum(axis=1)\n",
    "    \n",
    "    density = 1/((N-1)*np.sqrt(2*np.pi*width)**M+1e-100)*sQ\n",
    "    log_density = -log(N-1)-M/2*np.log(2*np.pi*width)+np.log(sQ)\n",
    "    return np.asarray(density), np.asarray(log_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GMM\n",
    "\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 20\n",
    "rcParams.update({'font.size': 30})\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "\n",
    "def encode_type(x):\n",
    "    if x == 'City':\n",
    "        return 0\n",
    "    elif x == 'Town':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "    \n",
    "def governing_encode(x):\n",
    "    if x == 'Conservative':\n",
    "        return 0\n",
    "    elif x == 'Left-wing':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def municipalityTypeEncoded(x):\n",
    " for index,type_ in enumerate(data.municipalityType.unique()):\n",
    "    if x == type_:\n",
    "        return index\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"simplified_municipality_indicators.csv\")\n",
    "\n",
    "data['typeEncoded'] = data['municipalityTypeBroad'].apply(encode_type)\n",
    "\n",
    "data['governingEncoded'] = data['governing'].apply(governing_encode)\n",
    "\n",
    "data['municipalityTypeEncoded'] = data['municipalityType'].apply(municipalityTypeEncoded)\n",
    "\n",
    "\n",
    "city_index = data[data['typeEncoded'] == 0].index.tolist()\n",
    "town_index = data[data['typeEncoded'] == 1].index.tolist()\n",
    "rural_index = data[data['typeEncoded'] == 2].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for K=1\n",
      "\n",
      "Fitting model for K=2\n",
      "\n",
      "Fitting model for K=3\n",
      "\n",
      "Fitting model for K=4\n",
      "\n",
      "Fitting model for K=5\n",
      "\n",
      "Fitting model for K=6\n",
      "\n",
      "Fitting model for K=7\n",
      "\n",
      "Fitting model for K=8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_of_variables = ['cars','tractors','snowmobiles','motorcycles' ,'fokusRanking','population',\n",
    "                     'hasEducation','urbanDegree','reportedCrime','reportedCrime','rentalApartments',\n",
    "                     'youngUnskilled','asylumCosts','reportedCrimeVandalism']\n",
    "\n",
    "\n",
    "# list_of_variables = ['tractors','population']\n",
    "                     \n",
    "    \n",
    "# municipalityTypeEncoded\n",
    "# typeEncoded\n",
    "# governingEncoded\n",
    "y_variable = 'typeEncoded'\n",
    "\n",
    "X_to_transform = np.array(data[list_of_variables])\n",
    "X_normalized =  (X_to_transform - X_to_transform.mean()) / (X_to_transform.max() - X_to_transform.min())\n",
    "\n",
    "tsne_model = TSNE(n_components=2,random_state=0,perplexity=30,n_iter=300)\n",
    "X = tsne_model.fit_transform(X_normalized)\n",
    "colors = np.array(data[y_variable])\n",
    "\n",
    "\n",
    "\n",
    "# scatter(X_to_transform[:,0],X_to_transform[:,2],c=colors, s=300)\n",
    "\n",
    "# scatter(X[:,0],X[:,1],c=colors, s=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = np.matrix(data[y_variable])\n",
    "colors = np.matrix(data[y_variable])\n",
    "N, M = X.shape\n",
    "\n",
    "# Range of K's to try\n",
    "KRange = range(1,10)\n",
    "T = len(KRange)\n",
    "\n",
    "covar_type = 'full'     # you can try out 'diag' as well\n",
    "reps = 3                # number of fits with different initalizations, best result will be kept\n",
    "\n",
    "# Allocate variables\n",
    "BIC = np.zeros((T,1))\n",
    "AIC = np.zeros((T,1))\n",
    "CVE = np.zeros((T,1))\n",
    "\n",
    "\n",
    "\n",
    "# K-fold crossvalidation\n",
    "CV = cross_validation.KFold(N,10,shuffle=True)\n",
    "\n",
    "for t,K in enumerate(KRange):\n",
    "        print('Fitting model for K={0}\\n'.format(K))\n",
    "\n",
    "        # Fit Gaussian mixture model\n",
    "        gmm = GMM(n_components=K, covariance_type=covar_type, n_init=reps, params='wmc').fit(X)\n",
    "\n",
    "        # Get BIC and AIC\n",
    "        BIC[t,0] = gmm.bic(X)\n",
    "        AIC[t,0] = gmm.aic(X)\n",
    "\n",
    "        # For each crossvalidation fold\n",
    "        for train_index, test_index in CV:\n",
    "\n",
    "            # extract training and test set for current CV fold\n",
    "            X_train = X[train_index]\n",
    "            X_test = X[test_index]\n",
    "\n",
    "            # Fit Gaussian mixture model to X_train\n",
    "            gmm = GMM(n_components=K, covariance_type=covar_type, n_init=reps, params='wmc').fit(X_train)\n",
    "\n",
    "            # compute negative log likelihood of X_test\n",
    "            CVE[t] += -gmm.score(X_test).sum()\n",
    "            \n",
    "\n",
    "# Plot results\n",
    "\n",
    "figure(1); hold(True)\n",
    "plt.plot(KRange, BIC)\n",
    "plt.plot(KRange, AIC)\n",
    "plt.plot(KRange, 2*CVE)\n",
    "plt.legend(['BIC', 'AIC', 'Crossvalidation'])\n",
    "plt.xlabel('K')\n",
    "plt.savefig(\"crossvalidation_GMM\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "list_of_variables = ['cars','tractors','snowmobiles','motorcycles' ,'fokusRanking','population',\n",
    "                     'hasEducation','urbanDegree','reportedCrime','reportedCrime','rentalApartments',\n",
    "                     'youngUnskilled','asylumCosts','reportedCrimeVandalism']\n",
    "                     \n",
    "\n",
    "\n",
    "X_to_transform = np.array(data[list_of_variables])\n",
    "X_normalized =  (X_to_transform - X_to_transform.mean()) / (X_to_transform.max() - X_to_transform.min())\n",
    "\n",
    "tsne_model = TSNE(n_components=2,random_state=0,perplexity=30,n_iter=200)\n",
    "X_reduced_with_TSNE = tsne_model.fit_transform(X_normalized)\n",
    "\n",
    "colors = np.array(data[y_variable])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(X_reduced_with_TSNE[city_index,0],X_reduced_with_TSNE[city_index,1],c='k', s=300,label=colors)\n",
    "plt.scatter(X_reduced_with_TSNE[town_index,0],X_reduced_with_TSNE[town_index,1],c='c', s=300,label=colors)\n",
    "plt.scatter(X_reduced_with_TSNE[rural_index,0],X_reduced_with_TSNE[rural_index,1],c='g', s=300,label=colors)\n",
    "\n",
    "plt.legend(['City', 'Town', 'Rural'])\n",
    "plt.savefig(\"Scatterplot_muni_type\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y = np.matrix(data[y_variable])\n",
    "colors = np.matrix(data[y_variable])\n",
    "N, M = X_reduced_with_TSNE.shape\n",
    "\n",
    "K = CVE.argmin() + 1\n",
    "cov_type = 'full'       \n",
    "# type of covariance, you can try out 'diag' as well\n",
    "reps = 3                \n",
    "# number of fits with different initalizations, best result will be kept\n",
    "# Fit Gaussian mixture model\n",
    "gmm = GMM(n_components=K, covariance_type=cov_type, n_init=reps, params='wmc').fit(X_reduced_with_TSNE)\n",
    "cls = gmm.predict(X_reduced_with_TSNE)    \n",
    "# extract cluster labels\n",
    "cds = gmm.means_        \n",
    "# extract cluster centroids (means of gaussians)\n",
    "covs = gmm.covars_      \n",
    "# extract cluster shapes (covariances of gaussians)\n",
    "if cov_type == 'diag':\n",
    "\n",
    "    new_covs = np.zeros([K,M,M])\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for elem in covs:\n",
    "\n",
    "        temp_m = np.zeros([M,M])\n",
    "\n",
    "        for i in range(len(elem)):\n",
    "\n",
    "            temp_m[i][i] = elem[i]\n",
    "\n",
    "        new_covs[count] = temp_m\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    covs = new_covs\n",
    "\n",
    "\n",
    "\n",
    "# Plot results:\n",
    "\n",
    "figure(figsize=(14,9))\n",
    "\n",
    "clusterplot(X_reduced_with_TSNE, clusterid=cls, centroids=cds, y=y, covars=covs)\n",
    "plt.savefig(\"cluster_plot\")\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
