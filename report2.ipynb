{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pivottablejs import pivot_ui\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import preprocessing \n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 20\n",
    "rcParams.update({'font.size': 30})\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "data = pd.read_csv(\"cleanSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "x = np.matrix(data['population'])\n",
    "y = np.matrix(data['Cases'])\n",
    "\n",
    "\n",
    "training_x = x[0,:261].T\n",
    "traning_y = y[0,:261].T\n",
    "\n",
    "test_x = x[0,261:].T\n",
    "test_y = y[0,261:].T\n",
    "\n",
    "\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(training_x,traning_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0\n"
     ]
    }
   ],
   "source": [
    "error = test_y.T -np.matrix(classifier.predict(test_x))\n",
    "\n",
    "print np.sqrt(np.square(error)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 5 0 0 0 1 0 0 0 1 0 0 0 0 0 2 0 0 0 7 0 1 0 0 0 0 0 0]\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 0 0 3 0 0 0 0 1 0 7 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "x = np.matrix(data.drop('Cases',axis=1).dropna())\n",
    "y = np.matrix(data['Cases'])\n",
    "\n",
    "\n",
    "training_x = x[:261,:]\n",
    "training_y = y[0,:261].T\n",
    "\n",
    "test_x = x[261:,:]\n",
    "test_y = y[0,261:].T\n",
    "\n",
    "\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(training_x,training_y)\n",
    "\n",
    "print classifier.predict(test_x)\n",
    "print test_y.T[0,:]\n",
    "#The tree classifier is not performing that well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 15)\n",
      "(261, 1)\n"
     ]
    }
   ],
   "source": [
    "print training_x.shape\n",
    "print training_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0]\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0]]\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "x = np.matrix(data.drop('Cases',axis=1).dropna())\n",
    "y = np.matrix(data['Cases'].apply(f))\n",
    "\n",
    "training_x = x[:261,:]\n",
    "training_y = y[0,:261].T\n",
    "\n",
    "test_x = x[261:,:]\n",
    "test_y = y[0,261:].T\n",
    "\n",
    "\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier(min_samples_split=100)\n",
    "classifier.fit(training_x,training_y)\n",
    "\n",
    "print classifier.predict(test_x)\n",
    "print test_y.T[0,:]\n",
    "    \n",
    "\n",
    "error = test_y.T[0,:] - classifier.predict(test_x)\n",
    "print np.sqrt(np.square(error)).sum()\n",
    "#In the binary case it is performing abit better when classifiing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda2/envs/deeplearning/lib/python2.7/site-packages/ipykernel/__main__.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0]]\n",
      "0.827586206897\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "x = np.matrix(data.drop('Cases',axis=1).dropna())\n",
    "y = np.matrix(data['Cases'].apply(f))\n",
    "\n",
    "training_x = x[:261,:]\n",
    "training_y = y[0,:261].T\n",
    "\n",
    "test_x = x[261:,:]\n",
    "test_y = y[0,261:].T\n",
    "\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(training_x,training_y)\n",
    "\n",
    "print classifier.predict(test_x)\n",
    "print test_y.T[0,:]\n",
    "    \n",
    "\n",
    "error = test_y.T[0,:] - classifier.predict(test_x)\n",
    "print 1- np.sqrt(np.square(error)).sum()/len(test_x)\n",
    "#Random forrest classifier has 82% accuracy on binary cases\n",
    "#Next step would be to use cross validation method. \n",
    "#k-fold validation or leave one out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0]\n",
      "[[0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0\n",
      "  0 0 0]]\n",
      "0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda2/envs/deeplearning/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "##Regression\n",
    "def f(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "import numpy as np\n",
    "\n",
    "x = np.matrix(data.drop('Cases',axis=1).dropna())\n",
    "y = np.matrix(data['Cases'].apply(f))\n",
    "\n",
    "count = 250\n",
    "\n",
    "training_x = x[:count,:]\n",
    "training_y = y[0,:count].T\n",
    "\n",
    "test_x = x[count:,:]\n",
    "test_y = y[0,count:].T\n",
    "\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(training_x,training_y)\n",
    "\n",
    "print classifier.predict(test_x)\n",
    "print test_y.T[0,:]\n",
    "\n",
    "\n",
    "error = test_y.T[0,:] - classifier.predict(test_x)\n",
    "print 1- np.sqrt(np.square(error)).sum()/len(test_x)\n",
    "#Logistic regression has 85% accuarcy on this partition.\n",
    "#Next step is to do crossvalidation aswell.\n",
    "#Also needs to be compared with the base case og guessing 0 all the time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case_popu = np.matrix(data[['Cases','population']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850826481239 Mean squared error\n",
      "Error (90, 1)\n"
     ]
    }
   ],
   "source": [
    "#Number of fire per 1000 \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "##Regression\n",
    "def f(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "import numpy as np\n",
    "\n",
    "x = np.matrix(data.drop(['Cases','population'],axis=1).dropna())\n",
    "# y = np.matrix((data['Cases'] / data['population']) *1e3)\n",
    "y = np.matrix(data['Cases'])\n",
    "\n",
    "count = 200\n",
    "\n",
    "training_x = x[:count,:]\n",
    "training_y = y[0,:count].T\n",
    "\n",
    "\n",
    "test_x = x[count:,:]\n",
    "test_y = y[0,count:].T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(training_x,training_y)\n",
    "\n",
    "\n",
    "error = test_y[:,0] - classifier.predict(test_x)\n",
    "# error = test_y[0,:] - test_y[0,:]\n",
    "print ( np.sqrt(np.square(error)).sum()/len(test_y)), \"Mean squared error\"\n",
    "print \"Error\" , error.shape\n",
    "#This regression problem is hard to relate to.\n",
    "#Option might be to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.matrix((data['Cases'] / data['population']) *1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.predict(test_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
